{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4508,"sourceType":"datasetVersion","datasetId":138},{"sourceId":6663,"sourceType":"datasetVersion","datasetId":3405}],"dockerImageVersionId":20477,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction to Recommendation Systems\n\nRecommendation systems are tools used to predict and suggest items to users based on their preferences and behaviors. These systems are widely used in various domains, including e-commerce, streaming platforms, social media, and more, to enhance user experience and engagement.\n\n### Movie Recommender Systems\n\nMovie recommender systems are a specific type of recommendation system that suggests movies to users based on their preferences, viewing history, and other relevant factors. These systems help users discover new movies they might enjoy, leading to increased user satisfaction and retention.\n\n### Types of Movie Recommender Systems\n\nThere are several types of movie recommender systems, each using different algorithms and approaches to generate recommendations:\n\n1. **Content-Based Filtering**: This approach recommends movies similar to those a user has liked in the past. It analyzes the content/features of movies (e.g., genre, actors, plot keywords) and suggests movies with similar characteristics.\n\n2. **Collaborative Filtering**:\n   - **User-Based Collaborative Filtering**: This method recommends movies based on the preferences of similar users. It identifies users with similar movie preferences and recommends movies liked by those users but not yet seen by the target user.\n   - **Item-Based Collaborative Filtering**: Instead of comparing users, this method compares movies directly. It recommends movies similar to those already liked by the user, based on the ratings or interactions of other users.\n\n3. **Hybrid Recommender Systems**: These systems combine multiple recommendation techniques to provide more accurate and diverse recommendations. For example, a hybrid system might combine content-based filtering with collaborative filtering to leverage the strengths of both approaches.\n\n4. **Matrix Factorization Methods**: These advanced techniques aim to model user-item interactions by decomposing the user-item interaction matrix into lower-dimensional matrices. Methods like Singular Value Decomposition (SVD) and Alternating Least Squares (ALS) are commonly used for matrix factorization in recommender systems.\n\n5. **Deep Learning-Based Recommender Systems**: With the advent of deep learning, neural network-based approaches have gained popularity in recommendation systems. Models like Neural Collaborative Filtering (NCF) and Deep Matrix Factorization (DMF) leverage deep learning architectures to capture complex user-item interactions and provide personalized recommendations.\n\nEach type of movie recommender system has its advantages and limitations, and the choice of algorithm depends on factors such as available data, scalability, and the specific requirements of the application.\n","metadata":{}},{"cell_type":"markdown","source":"### Why Content-Based Recommender Systems?\n- **Personalization**: Recommends items (movies) based on the characteristics of items and user preferences.\n- **Independence**: Doesn't rely on other users' behavior.\n- **Transparency**: Users can understand why a movie was recommended.\n","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering in Movie Recommendation System\n\n## 1. Removing Unnecessary Columns\n\n- Removed irrelevant columns from the dataset to streamline the data for analysis.\n- Columns such as 'homepage', 'tagline', 'budget', 'revenue', etc., were removed as they are not required for movie recommendations.\n\n## 2. Combining DataFrames\n\n- Merged two DataFrames containing movie metadata and credits information.\n- Utilized common identifiers such as movie IDs ('id') to merge the DataFrames efficiently.\n\n## 3. Creating New Columns\n\n- Introduced a new column named 'Director' to consolidate director information.\n- Extracted director names from the 'crew' column and populated the 'Director' column accordingly.\n","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning for Text Data\n\n## 1. Removing Empty Space\n\n- Trimmed leading and trailing white spaces from the text data.\n- Ensured consistency in text formatting and improved readability.\n\n## 2. Removing Special Characters\n\n- Eliminated special characters from the text data.\n- Special characters such as punctuation marks, symbols, etc., were removed to focus on meaningful content.\n\n## 3. Converting Text to Lowercase\n\n- Converted all text data to lowercase.\n- Standardized text formatting to ensure uniformity and facilitate analysis and modeling.\n\n## 4. Removing Stop Words\n\n- Eliminated common stop words from the text data.\n- Stop words such as 'the', 'a', 'an', etc., were removed to focus on relevant content.\n\n## 5. Replacing NaN Values\n\n- Replaced missing values (NaN) in the text data with empty strings.\n- Ensured consistency in data structure and facilitated further processing.","metadata":{}},{"cell_type":"markdown","source":"## TF-IDF for Text Vectorization\n\nTF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used in information retrieval and text mining to evaluate the importance of a word in a document relative to a collection of documents or corpus. It consists of two components:\n\n1. **Term Frequency (TF)**: Measures how often a term occurs in a document.\n\n2. **Inverse Document Frequency (IDF)**: Measures the rarity of a term across the corpus.\n\nThe TF-IDF score for a term in a document combines these components, capturing the importance of terms while reducing noise and providing flexibility in text representation.\n\nReasons for choosing TF-IDF:\n\n- **Term Importance**: TF-IDF captures the importance of terms by considering both frequency of occurrence and rarity across the corpus.\n- **Dimensionality Reduction**: TF-IDF reduces dimensionality by assigning lower weights to common terms and higher weights to rare terms.\n- **Noise Reduction**: Stop words and common terms have low TF-IDF scores, reducing noise in document representation.\n- **Flexibility**: Customizable parameters allow adaptation to different text mining tasks.\n","metadata":{}},{"cell_type":"markdown","source":"## Cosine Similarity in Recommendation Systems\n\n**Definition**: Cosine similarity measures the similarity between two vectors in an inner product space.\n\n**Why Use Cosine Similarity?**\n\n- **Scale-Invariance**: It is unaffected by the magnitude of vectors, making it suitable for comparing items with different scales.\n- **Efficiency**: Computationally efficient and effective for high-dimensional data in recommendation systems.\n- **Robustness**: Robust to outliers and noise, focusing on the angle between vectors rather than their absolute values.\n\n**Role in Recommendation Systems**\n\nCosine similarity is used to measure the similarity between items or users based on their feature vectors. It enables personalized recommendations by identifying items that are most similar to those previously liked by the user. In content-based recommendation systems, cosine similarity compares item feature vectors to make relevant recommendations.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # Import pandas library for data manipulation and analysis\n\nimport numpy as np  # Import numpy library for numerical computing\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer for converting text data to TF-IDF features\n\nfrom sklearn.metrics.pairwise import linear_kernel  # Import linear_kernel for computing similarity between vectors\n\nfrom ast import literal_eval  # Import literal_eval for safely evaluating string representations of Python data structures\n\nimport re # Import re for handling regular expression\n\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:06:50.322795Z","iopub.execute_input":"2024-03-11T07:06:50.323271Z","iopub.status.idle":"2024-03-11T07:06:50.331367Z","shell.execute_reply.started":"2024-03-11T07:06:50.323214Z","shell.execute_reply":"2024-03-11T07:06:50.330053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\n# Read the CSV file 'tmdb_5000_credits.csv' located in the '../input/tmdb-movie-metadata/' directory into a pandas DataFrame.\n# Assign the DataFrame to the variable 'df1'.\n\ndf2 = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')\n# Read the CSV file 'tmdb_5000_movies.csv' located in the '../input/tmdb-movie-metadata/' directory into a pandas DataFrame.\n# Assign the DataFrame to the variable 'df2'.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:06:52.061028Z","iopub.execute_input":"2024-03-11T07:06:52.061407Z","iopub.status.idle":"2024-03-11T07:06:53.249531Z","shell.execute_reply.started":"2024-03-11T07:06:52.061333Z","shell.execute_reply":"2024-03-11T07:06:53.248560Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(df1.head(2))\nprint(df2.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:06:55.646761Z","iopub.execute_input":"2024-03-11T07:06:55.647214Z","iopub.status.idle":"2024-03-11T07:06:55.719833Z","shell.execute_reply.started":"2024-03-11T07:06:55.647117Z","shell.execute_reply":"2024-03-11T07:06:55.718794Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"   movie_id                        ...                                                                       crew\n0     19995                        ...                          [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...\n1       285                        ...                          [{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...\n\n[2 rows x 4 columns]\n      budget    ...     vote_count\n0  237000000    ...          11800\n1  300000000    ...           4500\n\n[2 rows x 20 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df1.columns = ['id', 'title', 'cast', 'crew']\n# Rename the columns of DataFrame df1 to ['id', 'title', 'cast', 'crew'].\n# This line ensures that the columns of df1 have meaningful names.\n\ndf2 = df2.merge(df1, on='id')\n# Merge DataFrame df2 with DataFrame df1 based on the 'id' column.\n# This line combines the information from both DataFrames based on the common 'id' column, effectively joining them together.","metadata":{"_uuid":"c87bda9d56a936be126d03eda0bc743ee35be461","execution":{"iopub.status.busy":"2024-03-11T07:10:07.642617Z","iopub.execute_input":"2024-03-11T07:10:07.642945Z","iopub.status.idle":"2024-03-11T07:10:07.665056Z","shell.execute_reply.started":"2024-03-11T07:10:07.642897Z","shell.execute_reply":"2024-03-11T07:10:07.663739Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_director(x):\n    # Define a function named 'get_director' that takes a parameter 'x'.\n\n    for i in x:\n        # Iterate through each element 'i' in the input 'x'.\n\n        if i[\"job\"] == \"Director\":\n            # Check if the value associated with the key 'job' in 'i' is equal to \"Director\".\n\n            return i[\"name\"]\n            # If the condition is true, return the value associated with the key 'name' in 'i'.\n    return np.nan\n    # If the loop completes without finding a director, return 'np.nan' (numpy's representation of Not a Number).","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:18:05.765351Z","iopub.execute_input":"2024-03-11T07:18:05.766049Z","iopub.status.idle":"2024-03-11T07:18:05.771746Z","shell.execute_reply.started":"2024-03-11T07:18:05.765989Z","shell.execute_reply":"2024-03-11T07:18:05.770818Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"features = [\"cast\", \"crew\", \"keywords\", \"genres\"]\n# Define a list named 'features' containing the names of columns to be processed.\n\nfor feature in features:\n    # Iterate through each feature in the list 'features'.\n\n    df2[feature] = df2[feature].apply(literal_eval)\n    # Apply the literal_eval function to each element in the column specified by 'feature' in DataFrame df2.\n    # This function safely evaluates the string representation of Python data structures (e.g., lists of dictionaries).\n    # It converts the string representation of lists of dictionaries to actual lists of dictionaries.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:11.747877Z","iopub.execute_input":"2024-03-11T07:10:11.748433Z","iopub.status.idle":"2024-03-11T07:10:23.294580Z","shell.execute_reply.started":"2024-03-11T07:10:11.748364Z","shell.execute_reply":"2024-03-11T07:10:23.293514Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df2[\"director\"] = df2[\"crew\"].apply(get_director)\n# Create a new column named 'director' in DataFrame df2.\n# Apply the 'get_director' function to each element in the 'crew' column of df2.\n# The 'get_director' function extracts the name of the director from the crew list for each movie.\n# The extracted director names are then stored in the newly created 'director' column.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:26.181107Z","iopub.execute_input":"2024-03-11T07:10:26.181457Z","iopub.status.idle":"2024-03-11T07:10:26.204859Z","shell.execute_reply.started":"2024-03-11T07:10:26.181410Z","shell.execute_reply":"2024-03-11T07:10:26.204070Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def get_list(x):\n    # Define a function named 'get_list' that takes a parameter 'x'.\n\n    if isinstance(x, list):\n        # Check if 'x' is a list.\n\n        names = [i[\"name\"] for i in x]\n        # If 'x' is a list, create a list comprehension to extract the 'name' attribute from each dictionary 'i' in 'x'.\n        # Store the extracted names in the list 'names'.\n\n        if len(names) > 3:\n            # If the length of 'names' is greater than 3 (contains more than 3 elements),\n\n            names = names[:3]\n            # Keep only the first 3 elements in the list 'names'.\n\n        return names\n        # Return the list 'names'.\n\n    return []\n    # If 'x' is not a list (e.g., it is empty or not in the expected format), return an empty list.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:29.768331Z","iopub.execute_input":"2024-03-11T07:10:29.769060Z","iopub.status.idle":"2024-03-11T07:10:29.776265Z","shell.execute_reply.started":"2024-03-11T07:10:29.768987Z","shell.execute_reply":"2024-03-11T07:10:29.775108Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"features = [\"cast\", \"keywords\", \"genres\"]\n# Define a list named 'features' containing the names of columns to be processed.\n\nfor feature in features:\n    # Iterate through each feature in the list 'features'.\n\n    df2[feature] = df2[feature].apply(get_list)\n    # Apply the 'get_list' function to each element in the column specified by 'feature' in DataFrame df2.\n    # This function extracts a list of names from each element (which is assumed to be a list of dictionaries),\n    # and then updates the column with the extracted list of names.\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:34.478758Z","iopub.execute_input":"2024-03-11T07:10:34.479106Z","iopub.status.idle":"2024-03-11T07:10:34.595138Z","shell.execute_reply.started":"2024-03-11T07:10:34.479056Z","shell.execute_reply":"2024-03-11T07:10:34.594130Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df2 = df2[[\"original_title\", \"director\", \"overview\", \"genres\", \"cast\"]]\n# Select specific columns from DataFrame df2 using a list of column names.\n# Create a new DataFrame containing only the columns \"original_title\", \"director\", \"overview\", \"genres\", and \"cast\".","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:41.644949Z","iopub.execute_input":"2024-03-11T07:10:41.645684Z","iopub.status.idle":"2024-03-11T07:10:41.704905Z","shell.execute_reply.started":"2024-03-11T07:10:41.645626Z","shell.execute_reply":"2024-03-11T07:10:41.703682Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df2.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:45.535278Z","iopub.execute_input":"2024-03-11T07:10:45.535659Z","iopub.status.idle":"2024-03-11T07:10:45.564188Z","shell.execute_reply.started":"2024-03-11T07:10:45.535591Z","shell.execute_reply":"2024-03-11T07:10:45.562426Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                             original_title                        ...                                                                     cast\n0                                    Avatar                        ...                         [Sam Worthington, Zoe Saldana, Sigourney Weaver]\n1  Pirates of the Caribbean: At World's End                        ...                            [Johnny Depp, Orlando Bloom, Keira Knightley]\n\n[2 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_title</th>\n      <th>director</th>\n      <th>overview</th>\n      <th>genres</th>\n      <th>cast</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Avatar</td>\n      <td>James Cameron</td>\n      <td>In the 22nd century, a paraplegic Marine is di...</td>\n      <td>[Action, Adventure, Fantasy]</td>\n      <td>[Sam Worthington, Zoe Saldana, Sigourney Weaver]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>Gore Verbinski</td>\n      <td>Captain Barbossa, long believed to be dead, ha...</td>\n      <td>[Adventure, Fantasy, Action]</td>\n      <td>[Johnny Depp, Orlando Bloom, Keira Knightley]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2['cast'] = df2['cast'].str.join(' ')\n# Convert each element in the 'cast' column of DataFrame df2 to a string representation.\n# Join the elements of each list in the 'cast' column with a space (' ') separator.\n# Update the 'cast' column in df2 with the joined strings.\n\ndf2['genres'] = df2['genres'].str.join(' ')\n# Convert each element in the 'genres' column of DataFrame df2 to a string representation.\n# Join the elements of each list in the 'genres' column with a space (' ') separator.\n# Update the 'genres' column in df2 with the joined strings.\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:49.427290Z","iopub.execute_input":"2024-03-11T07:10:49.427646Z","iopub.status.idle":"2024-03-11T07:10:49.457566Z","shell.execute_reply.started":"2024-03-11T07:10:49.427590Z","shell.execute_reply":"2024-03-11T07:10:49.456321Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"df2['text'] = df2['overview'] + df2['cast'] + df2['genres'] + df2['director']\n# Concatenate the 'overview', 'cast', 'genres', and 'director' columns of DataFrame df2 into a single column named 'text'.\n# This creates a new column containing the combined textual information of these columns.","metadata":{"_uuid":"5e676c38ace04a24205b76b16dac0fa3e058027f","execution":{"iopub.status.busy":"2024-03-11T07:10:52.243458Z","iopub.execute_input":"2024-03-11T07:10:52.243858Z","iopub.status.idle":"2024-03-11T07:10:52.348317Z","shell.execute_reply.started":"2024-03-11T07:10:52.243794Z","shell.execute_reply":"2024-03-11T07:10:52.347428Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove any special characters except numbers and whitespace\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:10:58.642387Z","iopub.execute_input":"2024-03-11T07:10:58.643089Z","iopub.status.idle":"2024-03-11T07:10:58.648085Z","shell.execute_reply.started":"2024-03-11T07:10:58.643033Z","shell.execute_reply":"2024-03-11T07:10:58.647351Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df2['text'] = df2['text'].fillna('')\n# Fill any missing values (NaN) in the 'text' column of DataFrame df2 with an empty string ('').\n# This ensures that all values in the 'text' column are non-null.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:13:47.302534Z","iopub.execute_input":"2024-03-11T07:13:47.302868Z","iopub.status.idle":"2024-03-11T07:13:47.309612Z","shell.execute_reply.started":"2024-03-11T07:13:47.302819Z","shell.execute_reply":"2024-03-11T07:13:47.308441Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df2['text'] = df2['text'].apply(preprocess_text)\n# Apply the 'preprocess_text' function to each element in the 'text' column of DataFrame df2.\n# This function preprocesses each text by converting it to lowercase and removing special characters, as specified.","metadata":{"execution":{"iopub.status.busy":"2024-03-11T07:14:11.469449Z","iopub.execute_input":"2024-03-11T07:14:11.469822Z","iopub.status.idle":"2024-03-11T07:14:11.551605Z","shell.execute_reply.started":"2024-03-11T07:14:11.469767Z","shell.execute_reply":"2024-03-11T07:14:11.550385Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Define a TF-IDF Vectorizer Object. Remove all English stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english')\n# Initialize a TF-IDF Vectorizer object named 'tfidf'.\n# Set the parameter 'stop_words' to 'english' to remove common English stop words during tokenization.\n\n# Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(df2['text'])\n# Fit and transform the 'text' column of DataFrame df2 using the TF-IDF Vectorizer object 'tfidf'.\n# This process converts the text data into a TF-IDF matrix representation.\n\n# Output the shape of tfidf_matrix\ntfidf_matrix.shape\n# Print the shape of the TF-IDF matrix.\n# This provides information about the dimensions of the TF-IDF matrix, indicating the number of documents (rows) and unique words (columns).\n","metadata":{"_uuid":"a92da8cde39c61deef5a1b8efa31ed84cda7f5fe","execution":{"iopub.status.busy":"2024-03-11T07:14:14.643866Z","iopub.execute_input":"2024-03-11T07:14:14.644216Z","iopub.status.idle":"2024-03-11T07:14:15.199076Z","shell.execute_reply.started":"2024-03-11T07:14:14.644150Z","shell.execute_reply":"2024-03-11T07:14:15.198047Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(4803, 30178)"},"metadata":{}}]},{"cell_type":"code","source":"# Define the file path where you want to save the TF-IDF matrix\nfile_path = 'tfidf_matrix.pkl'\n\n# Save the TF-IDF matrix to a file using pickle\nwith open(file_path, 'wb') as f:\n    pickle.dump(tfidf_matrix, f)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T14:47:07.106063Z","iopub.execute_input":"2024-03-10T14:47:07.106505Z","iopub.status.idle":"2024-03-10T14:47:07.119478Z","shell.execute_reply.started":"2024-03-10T14:47:07.106422Z","shell.execute_reply":"2024-03-10T14:47:07.118166Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n# Calculate the cosine similarity between each pair of documents represented by rows in the TF-IDF matrix 'tfidf_matrix'.\n# The resulting 'cosine_sim' matrix contains pairwise cosine similarity scores between all documents in the dataset.\n# Each element (i, j) in the matrix represents the cosine similarity score between document i and document j.","metadata":{"_uuid":"5eb17d12220eecab4faf01bbfd13e79d8e446537","execution":{"iopub.status.busy":"2024-03-11T07:14:43.009411Z","iopub.execute_input":"2024-03-11T07:14:43.009802Z","iopub.status.idle":"2024-03-11T07:14:43.514886Z","shell.execute_reply.started":"2024-03-11T07:14:43.009731Z","shell.execute_reply":"2024-03-11T07:14:43.513878Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Construct a reverse map of indices and movie titles\nindices = pd.Series(df2.index, index=df2['original_title']).drop_duplicates()\n# Create a pandas Series named 'indices' where the index is set to the 'original_title' column of DataFrame df2.\n# The values of the Series are the corresponding indices of the DataFrame df2.\n# By setting the index to 'original_title', this creates a mapping of movie titles to their indices in the DataFrame.\n# Use drop_duplicates() to ensure that each movie title is associated with a unique index.","metadata":{"_uuid":"55df2df36be98e6dec5f617a5aa51b77c500faa4","execution":{"iopub.status.busy":"2024-03-11T07:17:24.930576Z","iopub.execute_input":"2024-03-11T07:17:24.930933Z","iopub.status.idle":"2024-03-11T07:17:24.938949Z","shell.execute_reply.started":"2024-03-11T07:17:24.930883Z","shell.execute_reply":"2024-03-11T07:17:24.937650Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwise similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return df2['original_title'].iloc[movie_indices]","metadata":{"_uuid":"9c383fcbb916dce464b01adf980d26ad96aebe0e","execution":{"iopub.status.busy":"2024-03-11T07:18:29.321577Z","iopub.execute_input":"2024-03-11T07:18:29.321920Z","iopub.status.idle":"2024-03-11T07:18:29.328347Z","shell.execute_reply.started":"2024-03-11T07:18:29.321868Z","shell.execute_reply":"2024-03-11T07:18:29.327641Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# The get_recommendations function will return the titles of the top 10 movies that are most similar to \"The Dark Knight Rises\" based on cosine similarity scores.\nget_recommendations('The Dark Knight Rises')","metadata":{"_uuid":"14d722124f82e69cb444adcc589e396c75cbb4ff","execution":{"iopub.status.busy":"2024-03-11T07:18:29.942069Z","iopub.execute_input":"2024-03-11T07:18:29.942394Z","iopub.status.idle":"2024-03-11T07:18:29.956886Z","shell.execute_reply.started":"2024-03-11T07:18:29.942344Z","shell.execute_reply":"2024-03-11T07:18:29.955907Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"428                              Batman Returns\n65                              The Dark Knight\n299                              Batman Forever\n1359                                     Batman\n119                               Batman Begins\n2507                                  Slow Burn\n3854    Batman: The Dark Knight Returns, Part 2\n210                              Batman & Robin\n1398                                  Max Payne\n9            Batman v Superman: Dawn of Justice\nName: original_title, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"get_recommendations('The Avengers')","metadata":{"_uuid":"902b9f1ab91921889c85e9008818dcc0b4710ccd","execution":{"iopub.status.busy":"2024-03-10T14:47:07.779928Z","iopub.execute_input":"2024-03-10T14:47:07.780411Z","iopub.status.idle":"2024-03-10T14:47:07.796518Z","shell.execute_reply.started":"2024-03-10T14:47:07.780229Z","shell.execute_reply":"2024-03-10T14:47:07.795083Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"7                   Avengers: Age of Ultron\n1294                               Serenity\n3144                                Plastic\n85      Captain America: The Winter Soldier\n26               Captain America: Civil War\n1715                                Timecop\n2136             Team America: World Police\n1286                            Snowpiercer\n588         Wall Street: Money Never Sleeps\n1161                     The Social Network\nName: original_title, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conclusion\n\nIn this project, we have successfully implemented a content-based recommendation system on a simpler and smaller scale. By leveraging techniques such as TF-IDF vectorization and cosine similarity, we were able to provide personalized recommendations based on the similarity of item features.\n\nLooking ahead, there are various advanced techniques such as deep learning-based models that can be explored to further enhance the recommendation system's accuracy and generate more personalized recommendations. Additionally, the implementation of a recommendation web service could extend the functionality to reach a wider audience and provide recommendations in real-time.\n\nBy continuously exploring and integrating different techniques and technologies, we can enhance the recommendation system's capabilities and provide users with more accurate and personalized recommendations tailored to their preferences.\n\n**Improvements:**\n- Enhance scalability and performance for larger datasets and growing user bases.\n- Optimize algorithms and data processing pipelines for faster recommendation generation.\n- Integrate real-time data streams for dynamic content updates to ensure recommendation relevance.\n\n","metadata":{}}]}